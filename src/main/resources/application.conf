inn.kafka-mimic {

  workers = 64
  batch.size = 1000

  source {
    whitelist = [".*"]
    blacklist = []

    zookeeper {
      connect = "127.0.0.1:2181/kafka"
      session.timeout.ms = 30000
      connection.timeout.ms = 3600000
      sync.time.ms = 30000
    }

    consumer {
      fetch.message.max.bytes = 262144
    }

    skip-corrupted = true
  }

  target {

    prefix = ""

    partitioning = preserve-partition // preserve-ordering, samza-friendly, random

    replication-factor = 0

    zookeeper {
      connect = "127.0.0.1:2181/kafka"
      session.timeout.ms = 30000
      connection.timeout.ms = 3600000
      sync.time.ms = 30000
    }

    producer {
      bootstrap.servers = "127.0.0.1:9092"
      acks = 1
      compression.type = none // we can't use compression with compacted topics yet
      retries = 10240
      max.request.size = 262144
    }
  }
}

inn.util {
  graphite {
    prefix = "inn"
  }
}


inn.util.loggers {
  "org.apache" = INFO
}

akka {
  loglevel = DEBUG
  log-dead-letters = 1

  log-config-on-start = on
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    debug {
      receive = off
      lifecycle = off
      autoreceive = off
      event-stream = off
    }

#    default-dispatcher {
#      fork-join-executor {
#        parallelism-factor = 3.0
#        parallelism-max = 64
#      }
#    }
  }
}
